# GitHubé‹ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ - ã‚¤ãƒ³ãƒ•ãƒ©/DevOpsãƒãƒ¼ãƒ ç‰ˆ

**ã‚¨ã‚¹ãƒ»ã‚¨ãƒ¼ãƒ»ã‚¨ã‚¹æ ªå¼ä¼šç¤¾ ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ»DevOpsãƒãƒ¼ãƒ å‘ã‘**  
*è‡ªå‹•åŒ–ã€ç›£è¦–ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–ã®ãŸã‚ã®å®Ÿè·µã‚¬ã‚¤ãƒ‰*

---

## ğŸ“š ç›®æ¬¡

1. [ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ è²¬å‹™ãƒãƒˆãƒªãƒƒã‚¯ã‚¹](#ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ è²¬å‹™ãƒãƒˆãƒªãƒƒã‚¯ã‚¹)
2. [CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†](#cicdãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†)
3. [ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ as Code](#ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£-as-code)
4. [ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ](#ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ)
5. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥](#ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥)
6. [é‹ç”¨è‡ªå‹•åŒ–](#é‹ç”¨è‡ªå‹•åŒ–)
7. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
8. [æˆåŠŸæŒ‡æ¨™ã¨SLO](#æˆåŠŸæŒ‡æ¨™ã¨slo)

---

## ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ è²¬å‹™ãƒãƒˆãƒªãƒƒã‚¯ã‚¹

### RACI ãƒãƒˆãƒªãƒƒã‚¯ã‚¹

| ã‚¿ã‚¹ã‚¯ | ã‚¤ãƒ³ãƒ•ãƒ© | é–‹ç™º | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ | PM |
|--------|----------|------|--------------|-----|
| CI/CDè¨­è¨ˆ | R/A | C | C | I |
| ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ | R/A | I | I | I |
| ç›£è¦–è¨­å®š | R/A | C | I | I |
| ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ | R | A | C | I |
| ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£è¨ˆç”» | R/A | C | I | I |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ›´æ–° | R | I | A | I |

*R=Responsible, A=Accountable, C=Consulted, I=Informed*

---

## CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†

### æ¨™æº–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹æˆ

```yaml
# .github/workflows/infra-standard-pipeline.yml
name: Infrastructure Standard Pipeline

on:
  push:
    branches: [main, staging, dev]
  pull_request:
    branches: [main]

env:
  AWS_REGION: ap-northeast-1
  TERRAFORM_VERSION: 1.5.0

jobs:
  infrastructure-validation:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          
      - name: Terraform Format Check
        run: terraform fmt -check -recursive
        
      - name: Terraform Validate
        run: |
          terraform init -backend=false
          terraform validate
          
      - name: Checkov Security Scan
        uses: bridgecrewio/checkov-action@master
        with:
          directory: ./terraform
          framework: terraform
          
      - name: Cost Estimation
        uses: infracost/infracost-action@v1
        with:
          path: ./terraform
          
  container-security:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Trivy Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'config'
          scan-ref: '.'
          
      - name: Dockerfile Lint
        uses: hadolint/hadolint-action@v3.1.0
        with:
          dockerfile: ./Dockerfile
          
  deployment:
    needs: [infrastructure-validation, container-security]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to AWS
        run: |
          # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
          ./scripts/deploy.sh ${{ github.sha }}
```

### ç’°å¢ƒåˆ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š

```yaml
# environments.yml
environments:
  development:
    auto_deploy: true
    approval_required: false
    rollback_enabled: true
    monitoring_level: basic
    
  staging:
    auto_deploy: true
    approval_required: true
    rollback_enabled: true
    monitoring_level: enhanced
    
  production:
    auto_deploy: false
    approval_required: true
    rollback_enabled: true
    monitoring_level: comprehensive
    blue_green_deployment: true
```

---

## ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ as Code

### Terraformæ¨™æº–æ§‹æˆ

```hcl
# terraform/modules/standard/main.tf
module "vpc" {
  source = "./modules/vpc"
  
  cidr_block = var.vpc_cidr
  availability_zones = var.availability_zones
  
  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
    Team        = "Infrastructure"
  }
}

module "ecs_cluster" {
  source = "./modules/ecs"
  
  cluster_name = "${var.project}-${var.environment}"
  vpc_id       = module.vpc.vpc_id
  subnets      = module.vpc.private_subnets
  
  autoscaling = {
    min_capacity = var.min_capacity
    max_capacity = var.max_capacity
    target_cpu   = 70
    target_memory = 80
  }
}

module "monitoring" {
  source = "./modules/monitoring"
  
  cluster_name = module.ecs_cluster.cluster_name
  
  alerts = {
    cpu_threshold    = 80
    memory_threshold = 85
    error_rate       = 0.01
  }
}
```

### Kubernetes ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç®¡ç†

```yaml
# k8s/base/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
  labels:
    app: myapp
    version: v1
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: app
        image: myapp:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

---

## ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### ç›£è¦–ã‚¹ã‚¿ãƒƒã‚¯æ§‹æˆ

```yaml
# monitoring/docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
    ports:
      - "9090:9090"
      
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
      
  alertmanager:
    image: prom/alertmanager:latest
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
      
  node_exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
```

### ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«å®šç¾©

```yaml
# alerts/infrastructure.yml
groups:
  - name: infrastructure
    interval: 30s
    rules:
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% (current value: {{ $value }}%)"
          
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space is below 10% (current value: {{ $value }}%)"
          
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Service down: {{ $labels.job }}"
          description: "{{ $labels.instance }} has been down for more than 1 minute"
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥

### Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

ENVIRONMENT=$1
VERSION=$2

echo "Starting Blue-Green deployment for $ENVIRONMENT with version $VERSION"

# 1. æ–°ç’°å¢ƒï¼ˆGreenï¼‰ã®æº–å‚™
echo "Preparing Green environment..."
terraform workspace select green-$ENVIRONMENT || terraform workspace new green-$ENVIRONMENT
terraform apply -var="version=$VERSION" -auto-approve

# 2. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "Running health checks..."
./scripts/health-check.sh green-$ENVIRONMENT
if [ $? -ne 0 ]; then
    echo "Health check failed. Rolling back..."
    terraform destroy -auto-approve
    exit 1
fi

# 3. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆ
echo "Switching traffic to Green..."
aws elb modify-load-balancer-attributes \
    --load-balancer-name $ENVIRONMENT-lb \
    --target-group-arn $(terraform output green_target_group_arn)

# 4. ç›£è¦–æœŸé–“
echo "Monitoring for 10 minutes..."
sleep 600

# 5. Blueç’°å¢ƒã®å‰Šé™¤
echo "Cleaning up Blue environment..."
terraform workspace select blue-$ENVIRONMENT
terraform destroy -auto-approve

echo "Blue-Green deployment completed successfully"
```

### ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```yaml
# k8s/canary-deployment.yaml
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: myapp
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  progressDeadlineSeconds: 60
  service:
    port: 80
    targetPort: 8080
  analysis:
    interval: 30s
    threshold: 5
    maxWeight: 50
    stepWeight: 10
    metrics:
    - name: request-success-rate
      thresholdRange:
        min: 99
      interval: 30s
    - name: request-duration
      thresholdRange:
        max: 500
      interval: 30s
    webhooks:
    - name: smoke-test
      url: http://flagger-loadtester.test/
      timeout: 15s
      metadata:
        type: smoke
        cmd: "curl -s http://myapp-canary.test/"
```

---

## é‹ç”¨è‡ªå‹•åŒ–

### è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®š

```hcl
# terraform/autoscaling.tf
resource "aws_autoscaling_policy" "scale_up" {
  name                   = "${var.name}-scale-up"
  scaling_adjustment     = 2
  adjustment_type        = "ChangeInCapacity"
  cooldown              = 300
  autoscaling_group_name = aws_autoscaling_group.main.name
}

resource "aws_cloudwatch_metric_alarm" "cpu_high" {
  alarm_name          = "${var.name}-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "120"
  statistic           = "Average"
  threshold           = "70"
  alarm_description   = "This metric monitors CPU utilization"
  alarm_actions       = [aws_autoscaling_policy.scale_up.arn]
}

resource "aws_autoscaling_policy" "scale_down" {
  name                   = "${var.name}-scale-down"
  scaling_adjustment     = -1
  adjustment_type        = "ChangeInCapacity"
  cooldown              = 300
  autoscaling_group_name = aws_autoscaling_group.main.name
}

resource "aws_cloudwatch_metric_alarm" "cpu_low" {
  alarm_name          = "${var.name}-cpu-low"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "120"
  statistic           = "Average"
  threshold           = "30"
  alarm_description   = "This metric monitors CPU utilization"
  alarm_actions       = [aws_autoscaling_policy.scale_down.arn]
}
```

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è‡ªå‹•åŒ–

```bash
#!/bin/bash
# scripts/automated-backup.sh

set -e

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/${TIMESTAMP}"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Backing up databases..."
for DB in $(mysql -e "SHOW DATABASES;" | grep -v Database); do
    mysqldump --single-transaction --routines --triggers \
              --databases $DB > ${BACKUP_DIR}/${DB}.sql
done

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Backing up filesystem..."
tar -czf ${BACKUP_DIR}/filesystem.tar.gz \
    --exclude=/backup \
    --exclude=/tmp \
    --exclude=/var/log \
    /

# S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
echo "Uploading to S3..."
aws s3 sync ${BACKUP_DIR} s3://backup-bucket/${TIMESTAMP}/ \
    --storage-class GLACIER

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤
echo "Cleaning up old backups..."
find /backup -type d -mtime +30 -exec rm -rf {} \;

echo "Backup completed: ${TIMESTAMP}"
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ãƒ“ãƒ«ãƒ‰æ™‚é–“æœ€é©åŒ–

```yaml
# .github/workflows/optimized-build.yml
name: Optimized Build Pipeline

on:
  push:
    branches: [main, dev]

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [api, web, worker]
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v2
        
      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
            
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: ./${{ matrix.service }}
          push: true
          tags: myapp/${{ matrix.service }}:${{ github.sha }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
          
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache
```

### CDNè¨­å®šæœ€é©åŒ–

```hcl
# terraform/cloudfront.tf
resource "aws_cloudfront_distribution" "main" {
  enabled             = true
  is_ipv6_enabled    = true
  default_root_object = "index.html"
  
  origin {
    domain_name = aws_s3_bucket.static.bucket_regional_domain_name
    origin_id   = "S3-${aws_s3_bucket.static.id}"
    
    s3_origin_config {
      origin_access_identity = aws_cloudfront_origin_access_identity.main.cloudfront_access_identity_path
    }
  }
  
  default_cache_behavior {
    allowed_methods  = ["GET", "HEAD", "OPTIONS"]
    cached_methods   = ["GET", "HEAD"]
    target_origin_id = "S3-${aws_s3_bucket.static.id}"
    
    forwarded_values {
      query_string = false
      cookies {
        forward = "none"
      }
    }
    
    viewer_protocol_policy = "redirect-to-https"
    min_ttl                = 0
    default_ttl            = 86400
    max_ttl                = 31536000
    compress               = true
  }
  
  ordered_cache_behavior {
    path_pattern     = "/api/*"
    allowed_methods  = ["GET", "HEAD", "OPTIONS", "PUT", "POST", "PATCH", "DELETE"]
    cached_methods   = ["GET", "HEAD"]
    target_origin_id = "ALB-${aws_lb.main.id}"
    
    forwarded_values {
      query_string = true
      headers      = ["*"]
      cookies {
        forward = "all"
      }
    }
    
    viewer_protocol_policy = "https-only"
    min_ttl                = 0
    default_ttl            = 0
    max_ttl                = 0
  }
}
```

---

## æˆåŠŸæŒ‡æ¨™ã¨SLO

### Service Level Objectives (SLO)

| ã‚µãƒ¼ãƒ“ã‚¹ | å¯ç”¨æ€§ | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (P99) | ã‚¨ãƒ©ãƒ¼ç‡ |
|----------|--------|------------------|----------|
| API | 99.9% | < 200ms | < 0.1% |
| Web | 99.95% | < 100ms | < 0.05% |
| Database | 99.99% | < 50ms | < 0.01% |

### ã‚¤ãƒ³ãƒ•ãƒ©KPI

```yaml
# metrics/infrastructure-kpi.yml
kpis:
  availability:
    target: 99.9%
    measurement: uptime / total_time * 100
    
  deployment_frequency:
    target: ">= 10 per week"
    measurement: count(deployments) / 7
    
  mttr:
    target: "< 30 minutes"
    measurement: avg(incident_resolution_time)
    
  infrastructure_cost:
    target: "< $10,000/month"
    measurement: sum(aws_costs + gcp_costs + azure_costs)
    
  resource_utilization:
    cpu:
      target: "60-80%"
      measurement: avg(cpu_usage)
    memory:
      target: "70-85%"
      measurement: avg(memory_usage)
    
  build_time:
    target: "< 5 minutes"
    measurement: avg(pipeline_duration)
    
  test_coverage:
    target: ">= 80%"
    measurement: covered_lines / total_lines * 100
```

### é€±æ¬¡é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
## ã‚¤ãƒ³ãƒ•ãƒ©é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ

### ã‚µãƒãƒªãƒ¼
- ç·ç¨¼åƒæ™‚é–“: XXXæ™‚é–“
- å¯ç”¨æ€§: XX.X%
- ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•°: Xä»¶
- ãƒ‡ãƒ—ãƒ­ã‚¤å›æ•°: Xå›

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ : XXms
- P99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: XXms
- ã‚¨ãƒ©ãƒ¼ç‡: X.XX%

### ã‚³ã‚¹ãƒˆ
- ä»Šé€±ã®è²»ç”¨: $X,XXX
- å‰é€±æ¯”: +/- X%
- äºˆç®—æ¶ˆåŒ–ç‡: XX%

### æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. [èª²é¡Œ] â†’ [å¯¾ç­–]
2. [èª²é¡Œ] â†’ [å¯¾ç­–]

### æ¥é€±ã®è¨ˆç”»
- [ ] ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­
- [ ] ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰è¨ˆç”»
- [ ] æœ€é©åŒ–ã‚¿ã‚¹ã‚¯
```

---

## ğŸ› ï¸ ã‚¤ãƒ³ãƒ•ãƒ©ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹

### å¿…é ˆCLIãƒ„ãƒ¼ãƒ«

```bash
# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#!/bin/bash

# AWS CLI
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip && ./aws/install

# Terraform
wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform

# kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/infra-health-check.sh

echo "=== Infrastructure Health Check ==="
echo

# AWSæ¥ç¶šç¢ºèª
echo "Checking AWS connectivity..."
aws sts get-caller-identity > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ“ AWS connection OK"
else
    echo "âœ— AWS connection FAILED"
fi

# Kubernetesæ¥ç¶šç¢ºèª
echo "Checking Kubernetes connectivity..."
kubectl cluster-info > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ“ Kubernetes connection OK"
else
    echo "âœ— Kubernetes connection FAILED"
fi

# Dockerç¢ºèª
echo "Checking Docker..."
docker version > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ“ Docker OK"
else
    echo "âœ— Docker FAILED"
fi

echo
echo "=== Health Check Complete ==="
```

---

## ğŸ“ ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ ã‚µãƒãƒ¼ãƒˆ

### ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †

1. **L1 - æƒ…å ±åé›†** (5åˆ†)
   - ãƒ­ã‚°ç¢ºèª
   - ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç¢ºèª
   - æœ€è¿‘ã®å¤‰æ›´ç¢ºèª

2. **L2 - åˆæœŸå¯¾å¿œ** (15åˆ†)
   - ä¸€æ™‚å¯¾å‡¦å®Ÿæ–½
   - å½±éŸ¿ç¯„å›²ç‰¹å®š
   - ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼é€šçŸ¥

3. **L3 - æ ¹æœ¬å¯¾å¿œ** (1æ™‚é–“)
   - æ ¹æœ¬åŸå› èª¿æŸ»
   - æ’ä¹…å¯¾ç­–å®Ÿæ–½
   - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

### é€£çµ¡å…ˆ

- **ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ **: infra@sas-com.com
- **24æ™‚é–“å¯¾å¿œ**: oncall@sas-com.com
- **Slackãƒãƒ£ãƒ³ãƒãƒ«**: #infra-team
- **PagerDuty**: sas-infrastructure

---

**æ›´æ–°æ—¥**: 2025-09-11  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**å¯¾è±¡**: ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ»DevOpsãƒãƒ¼ãƒ 