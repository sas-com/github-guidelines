#!/usr/bin/env python3
"""
GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ãƒ„ãƒ¼ãƒ«
ã‚¨ã‚¹ãƒ»ã‚¨ãƒ¼ãƒ»ã‚¨ã‚¹æ ªå¼ä¼šç¤¾
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0

é«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æã¨æ¤œè¨¼ã‚’å®Ÿè¡Œ
"""

import os
import sys
import yaml
import json
import argparse
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging


class Severity(Enum):
    """å•é¡Œã®é‡è¦åº¦"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


@dataclass
class ValidationIssue:
    """æ¤œè¨¼ã§è¦‹ã¤ã‹ã£ãŸå•é¡Œ"""
    severity: Severity
    category: str
    message: str
    file_path: str
    line_number: Optional[int] = None
    column_number: Optional[int] = None
    suggestion: Optional[str] = None
    rule_id: Optional[str] = None


@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    passed: bool
    issues: List[ValidationIssue] = field(default_factory=list)
    warnings: List[ValidationIssue] = field(default_factory=list)
    stats: Dict[str, Any] = field(default_factory=dict)


class WorkflowValidator:
    """GitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config = self._load_config(config_path)
        self.logger = logging.getLogger(__name__)
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.security_patterns = {
            'hardcoded_secrets': [
                r'(password|token|key|secret|api[_-]?key)\s*[:=]\s*["\'][^"\']{8,}["\']',
                r'(aws[_-]?access[_-]?key|aws[_-]?secret|github[_-]?token)\s*[:=]',
            ],
            'dangerous_commands': [
                r'curl\s+.*\|\s*(bash|sh|zsh)',
                r'wget\s+.*-O.*\|\s*(bash|sh|zsh)',
                r'eval\s*\$\(',
                r'\$\{.*\}.*\|\s*(bash|sh|zsh)',
            ],
            'unsafe_checkout': [
                r'actions/checkout@(main|master|HEAD)',
                r'checkout@v[0-9]+(?:\.[0-9]+)*$',  # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ãªã„å ´åˆ
            ],
        }
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã®è¨­å®š
        self.performance_thresholds = {
            'max_jobs': 50,
            'max_steps_per_job': 30,
            'max_workflow_timeout': 360,  # 6æ™‚é–“
            'recommended_cache_actions': [
                'actions/cache',
                'actions/setup-node',
                'actions/setup-python',
                'actions/setup-java',
            ],
        }

    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        default_config = {
            'rules': {
                'require_timeout': True,
                'require_name': True,
                'check_security': True,
                'check_performance': True,
                'check_best_practices': True,
            },
            'severity_levels': {
                'missing_timeout': 'medium',
                'hardcoded_secrets': 'critical',
                'unsafe_actions': 'high',
                'performance_issues': 'medium',
            }
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = yaml.safe_load(f)
                default_config.update(user_config)
            except Exception as e:
                self.logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return default_config

    def validate_directory(self, directory_path: str) -> ValidationResult:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œè¨¼"""
        workflows_path = Path(directory_path) / '.github' / 'workflows'
        
        if not workflows_path.exists():
            return ValidationResult(
                passed=False,
                issues=[ValidationIssue(
                    severity=Severity.CRITICAL,
                    category="structure",
                    message="workflows ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“",
                    file_path=str(workflows_path),
                    rule_id="MISSING_WORKFLOWS_DIR"
                )]
            )
        
        all_issues = []
        all_warnings = []
        stats = {
            'total_workflows': 0,
            'valid_workflows': 0,
            'invalid_workflows': 0,
            'total_jobs': 0,
            'total_steps': 0,
        }
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        workflow_files = list(workflows_path.glob('*.yml')) + list(workflows_path.glob('*.yaml'))
        stats['total_workflows'] = len(workflow_files)
        
        for workflow_file in workflow_files:
            result = self.validate_workflow(str(workflow_file))
            
            if result.passed:
                stats['valid_workflows'] += 1
            else:
                stats['invalid_workflows'] += 1
            
            all_issues.extend(result.issues)
            all_warnings.extend(result.warnings)
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            if 'jobs_count' in result.stats:
                stats['total_jobs'] += result.stats['jobs_count']
            if 'steps_count' in result.stats:
                stats['total_steps'] += result.stats['steps_count']
        
        # å…¨ä½“çš„ãªãƒã‚§ãƒƒã‚¯
        all_issues.extend(self._check_overall_structure(directory_path))
        
        return ValidationResult(
            passed=len([i for i in all_issues if i.severity in [Severity.CRITICAL, Severity.HIGH]]) == 0,
            issues=all_issues,
            warnings=all_warnings,
            stats=stats
        )

    def validate_workflow(self, file_path: str) -> ValidationResult:
        """å˜ä¸€ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼"""
        issues = []
        warnings = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                workflow_data = yaml.safe_load(content)
        except yaml.YAMLError as e:
            return ValidationResult(
                passed=False,
                issues=[ValidationIssue(
                    severity=Severity.CRITICAL,
                    category="syntax",
                    message=f"YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    file_path=file_path,
                    rule_id="YAML_SYNTAX_ERROR"
                )]
            )
        except Exception as e:
            return ValidationResult(
                passed=False,
                issues=[ValidationIssue(
                    severity=Severity.CRITICAL,
                    category="file",
                    message=f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    file_path=file_path,
                    rule_id="FILE_READ_ERROR"
                )]
            )
        
        if not isinstance(workflow_data, dict):
            return ValidationResult(
                passed=False,
                issues=[ValidationIssue(
                    severity=Severity.CRITICAL,
                    category="structure",
                    message="ç„¡åŠ¹ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹é€ ",
                    file_path=file_path,
                    rule_id="INVALID_STRUCTURE"
                )]
            )
        
        # å„ç¨®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        issues.extend(self._check_required_fields(workflow_data, file_path))
        issues.extend(self._check_security(workflow_data, file_path, content))
        issues.extend(self._check_performance(workflow_data, file_path))
        issues.extend(self._check_best_practices(workflow_data, file_path))
        
        warnings.extend(self._check_recommendations(workflow_data, file_path))
        
        # çµ±è¨ˆæƒ…å ±ã‚’åé›†
        stats = self._collect_stats(workflow_data)
        
        # çµæœåˆ¤å®š
        critical_issues = [i for i in issues if i.severity == Severity.CRITICAL]
        
        return ValidationResult(
            passed=len(critical_issues) == 0,
            issues=issues,
            warnings=warnings,
            stats=stats
        )

    def _check_required_fields(self, workflow: Dict[str, Any], file_path: str) -> List[ValidationIssue]:
        """å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        required_fields = ['on', 'jobs']
        for field in required_fields:
            if field not in workflow:
                issues.append(ValidationIssue(
                    severity=Severity.CRITICAL,
                    category="structure",
                    message=f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒã‚ã‚Šã¾ã›ã‚“",
                    file_path=file_path,
                    suggestion=f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã« '{field}' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„",
                    rule_id=f"MISSING_{field.upper()}"
                ))
        
        # åå‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¨å¥¨
        if 'name' not in workflow and self.config['rules']['require_name']:
            issues.append(ValidationIssue(
                severity=Severity.MEDIUM,
                category="structure",
                message="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                file_path=file_path,
                suggestion="ã‚ã‹ã‚Šã‚„ã™ã„ 'name' ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™",
                rule_id="MISSING_NAME"
            ))
        
        return issues

    def _check_security(self, workflow: Dict[str, Any], file_path: str, content: str) -> List[ValidationIssue]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        if not self.config['rules']['check_security']:
            return issues
        
        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®æ¤œå‡º
        for pattern_name, patterns in self.security_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    issues.append(ValidationIssue(
                        severity=Severity.CRITICAL,
                        category="security",
                        message=f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯: {pattern_name}ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ",
                        file_path=file_path,
                        line_number=line_num,
                        suggestion="ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã¯GitHub Secretsã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                        rule_id=f"SECURITY_{pattern_name.upper()}"
                    ))
        
        # permissions ã®æ¤œè¨¼
        if 'permissions' in workflow:
            perms = workflow['permissions']
            if perms == 'write-all' or (isinstance(perms, dict) and 'write-all' in perms.values()):
                issues.append(ValidationIssue(
                    severity=Severity.HIGH,
                    category="security",
                    message="éå‰°ãªæ¨©é™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ (write-all)",
                    file_path=file_path,
                    suggestion="å¿…è¦æœ€å°é™ã®æ¨©é™ã®ã¿ã‚’æŒ‡å®šã—ã¦ãã ã•ã„",
                    rule_id="EXCESSIVE_PERMISSIONS"
                ))
        
        # pull_request_target ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        if 'on' in workflow:
            triggers = workflow['on']
            if isinstance(triggers, dict) and 'pull_request_target' in triggers:
                # å®‰å…¨ãªã‚¬ãƒ¼ãƒ‰ã®ç¢ºèª
                safe_guard_found = False
                if 'jobs' in workflow:
                    for job in workflow['jobs'].values():
                        if isinstance(job, dict) and 'if' in job:
                            if 'github.event.pull_request.head.repo.full_name' in str(job['if']):
                                safe_guard_found = True
                                break
                
                if not safe_guard_found:
                    issues.append(ValidationIssue(
                        severity=Severity.CRITICAL,
                        category="security",
                        message="pull_request_targetã®å®‰å…¨ã§ãªã„ä½¿ç”¨",
                        file_path=file_path,
                        suggestion="ãƒ•ã‚©ãƒ¼ã‚¯ã‹ã‚‰ã®PRã«å¯¾ã™ã‚‹å®‰å…¨ã‚¬ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„",
                        rule_id="UNSAFE_PR_TARGET"
                    ))
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šãƒã‚§ãƒƒã‚¯
        self._check_action_versions(workflow, file_path, issues)
        
        return issues

    def _check_action_versions(self, workflow: Dict[str, Any], file_path: str, issues: List[ValidationIssue]):
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šã‚’ãƒã‚§ãƒƒã‚¯"""
        if 'jobs' not in workflow:
            return
        
        for job_name, job in workflow['jobs'].items():
            if not isinstance(job, dict) or 'steps' not in job:
                continue
            
            for step_idx, step in enumerate(job['steps']):
                if not isinstance(step, dict) or 'uses' not in step:
                    continue
                
                uses = step['uses']
                # ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿ã®æŒ‡å®šï¼ˆå±é™ºï¼‰
                if re.match(r'^[^@]+@v\d+$', uses):
                    issues.append(ValidationIssue(
                        severity=Severity.HIGH,
                        category="security",
                        message=f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ '{uses}' ãŒãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿å›ºå®š",
                        file_path=file_path,
                        suggestion="ã‚»ãƒŸãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¾ã§å›ºå®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ (ä¾‹: @v1.2.3)",
                        rule_id="ACTION_VERSION_PINNING"
                    ))
                
                # ãƒ–ãƒ©ãƒ³ãƒæŒ‡å®šï¼ˆå±é™ºï¼‰
                elif re.match(r'^[^@]+@(main|master|develop|HEAD)$', uses):
                    issues.append(ValidationIssue(
                        severity=Severity.CRITICAL,
                        category="security",
                        message=f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ '{uses}' ãŒä¸å®‰å®šãªãƒ–ãƒ©ãƒ³ãƒã‚’å‚ç…§",
                        file_path=file_path,
                        suggestion="å…·ä½“çš„ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„",
                        rule_id="ACTION_BRANCH_REFERENCE"
                    ))

    def _check_performance(self, workflow: Dict[str, Any], file_path: str) -> List[ValidationIssue]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        if not self.config['rules']['check_performance']:
            return issues
        
        if 'jobs' not in workflow:
            return issues
        
        jobs = workflow['jobs']
        
        # ã‚¸ãƒ§ãƒ–æ•°ã®ãƒã‚§ãƒƒã‚¯
        if len(jobs) > self.performance_thresholds['max_jobs']:
            issues.append(ValidationIssue(
                severity=Severity.MEDIUM,
                category="performance",
                message=f"ã‚¸ãƒ§ãƒ–æ•°ãŒå¤šã™ãã¾ã™ ({len(jobs)} > {self.performance_thresholds['max_jobs']})",
                file_path=file_path,
                suggestion="ã‚¸ãƒ§ãƒ–ã‚’ã‚ˆã‚ŠåŠ¹ç‡çš„ã«çµ±åˆã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                rule_id="TOO_MANY_JOBS"
            ))
        
        for job_name, job in jobs.items():
            if not isinstance(job, dict):
                continue
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
            if 'timeout-minutes' not in job and self.config['rules']['require_timeout']:
                issues.append(ValidationIssue(
                    severity=Severity.MEDIUM,
                    category="performance",
                    message=f"ã‚¸ãƒ§ãƒ– '{job_name}' ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                    file_path=file_path,
                    suggestion="timeout-minutesã‚’è¨­å®šã—ã¦ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’åˆ¶å¾¡ã—ã¦ãã ã•ã„",
                    rule_id="MISSING_TIMEOUT"
                ))
            elif 'timeout-minutes' in job:
                timeout = job['timeout-minutes']
                if timeout > self.performance_thresholds['max_workflow_timeout']:
                    issues.append(ValidationIssue(
                        severity=Severity.MEDIUM,
                        category="performance",
                        message=f"ã‚¸ãƒ§ãƒ– '{job_name}' ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒé•·ã™ãã¾ã™ ({timeout}åˆ†)",
                        file_path=file_path,
                        suggestion=f"{self.performance_thresholds['max_workflow_timeout']}åˆ†ä»¥ä¸‹ã«è¨­å®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨",
                        rule_id="LONG_TIMEOUT"
                    ))
            
            # ã‚¹ãƒ†ãƒƒãƒ—æ•°ãƒã‚§ãƒƒã‚¯
            if 'steps' in job:
                steps_count = len(job['steps'])
                if steps_count > self.performance_thresholds['max_steps_per_job']:
                    issues.append(ValidationIssue(
                        severity=Severity.MEDIUM,
                        category="performance",
                        message=f"ã‚¸ãƒ§ãƒ– '{job_name}' ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå¤šã™ãã¾ã™ ({steps_count})",
                        file_path=file_path,
                        suggestion="ã‚¸ãƒ§ãƒ–ã‚’åˆ†å‰²ã™ã‚‹ã‹ã€ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ±åˆã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                        rule_id="TOO_MANY_STEPS"
                    ))
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ã®ç¢ºèª
                self._check_cache_usage(job, job_name, file_path, issues)
        
        return issues

    def _check_cache_usage(self, job: Dict[str, Any], job_name: str, file_path: str, issues: List[ValidationIssue]):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ã®ç¢ºèª"""
        if 'steps' not in job:
            return
        
        # ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’æ¤œå‡º
        package_managers = []
        cache_used = False
        
        for step in job['steps']:
            if not isinstance(step, dict):
                continue
            
            # run ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’æ¤œå‡º
            if 'run' in step:
                run_command = step['run'].lower()
                if any(pm in run_command for pm in ['npm install', 'yarn install', 'pip install', 'mvn', 'gradle']):
                    if 'npm' in run_command:
                        package_managers.append('npm')
                    if 'yarn' in run_command:
                        package_managers.append('yarn')
                    if 'pip' in run_command:
                        package_managers.append('pip')
                    if 'mvn' in run_command:
                        package_managers.append('maven')
                    if 'gradle' in run_command:
                        package_managers.append('gradle')
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ä½¿ç”¨ã‚’ç¢ºèª
            if 'uses' in step:
                uses = step['uses']
                if any(cache_action in uses for cache_action in self.performance_thresholds['recommended_cache_actions']):
                    cache_used = True
        
        # ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„å ´åˆ
        if package_managers and not cache_used:
            issues.append(ValidationIssue(
                severity=Severity.MEDIUM,
                category="performance",
                message=f"ã‚¸ãƒ§ãƒ– '{job_name}' ã§ä¾å­˜é–¢ä¿‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                file_path=file_path,
                suggestion=f"æ¤œå‡ºã•ã‚ŒãŸä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ„ãƒ¼ãƒ«: {', '.join(set(package_managers))}",
                rule_id="MISSING_CACHE"
            ))

    def _check_best_practices(self, workflow: Dict[str, Any], file_path: str) -> List[ValidationIssue]:
        """ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        if not self.config['rules']['check_best_practices']:
            return issues
        
        # ç’°å¢ƒå¤‰æ•°ã®è¨­å®šæ–¹æ³•ãƒã‚§ãƒƒã‚¯
        if 'env' in workflow:
            for key, value in workflow['env'].items():
                if isinstance(value, str) and len(value) > 100:
                    issues.append(ValidationIssue(
                        severity=Severity.LOW,
                        category="best_practices",
                        message=f"ç’°å¢ƒå¤‰æ•° '{key}' ã®å€¤ãŒé•·ã™ãã¾ã™",
                        file_path=file_path,
                        suggestion="é•·ã„å€¤ã¯Secretsã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                        rule_id="LONG_ENV_VALUE"
                    ))
        
        # concurrency ã®ä½¿ç”¨æ¨å¥¨
        if 'concurrency' not in workflow:
            # PRãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å ´åˆã¯ concurrency ã‚’æ¨å¥¨
            if self._is_pr_workflow(workflow):
                issues.append(ValidationIssue(
                    severity=Severity.LOW,
                    category="best_practices",
                    message="PRãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«concurrencyã®è¨­å®šã‚’æ¨å¥¨",
                    file_path=file_path,
                    suggestion="åŒã˜PRã«å¯¾ã™ã‚‹è¤‡æ•°å®Ÿè¡Œã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚concurrencyã‚’è¨­å®šã—ã¦ãã ã•ã„",
                    rule_id="MISSING_CONCURRENCY"
                ))
        
        return issues

    def _check_recommendations(self, workflow: Dict[str, Any], file_path: str) -> List[ValidationIssue]:
        """æ¨å¥¨äº‹é …ãƒã‚§ãƒƒã‚¯ï¼ˆè­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼‰"""
        warnings = []
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ–ãƒ©ãƒ³ãƒä»¥å¤–ã§ã®å®Ÿè¡Œãƒã‚§ãƒƒã‚¯
        if 'on' in workflow:
            triggers = workflow['on']
            if isinstance(triggers, dict):
                if 'push' in triggers:
                    push_config = triggers['push']
                    if isinstance(push_config, dict) and 'branches' not in push_config:
                        warnings.append(ValidationIssue(
                            severity=Severity.INFO,
                            category="recommendations",
                            message="pushãƒˆãƒªã‚¬ãƒ¼ã§ãƒ–ãƒ©ãƒ³ãƒåˆ¶é™ã®è¨­å®šã‚’æ¨å¥¨",
                            file_path=file_path,
                            suggestion="ä¸è¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ–ãƒ©ãƒ³ãƒã‚’æŒ‡å®šã—ã¦ãã ã•ã„",
                            rule_id="UNRESTRICTED_PUSH"
                        ))
        
        return warnings

    def _check_overall_structure(self, directory_path: str) -> List[ValidationIssue]:
        """å…¨ä½“æ§‹é€ ã®ãƒã‚§ãƒƒã‚¯"""
        issues = []
        path = Path(directory_path)
        
        # åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ãƒã‚§ãƒƒã‚¯
        recommended_files = {
            '.github/CODEOWNERS': "ã‚³ãƒ¼ãƒ‰ã‚ªãƒ¼ãƒŠãƒ¼ã‚·ãƒƒãƒ—ã®æ˜ç¢ºåŒ–",
            '.github/dependabot.yml': "è‡ªå‹•ä¾å­˜é–¢ä¿‚æ›´æ–°",
            '.github/ISSUE_TEMPLATE': "Issue ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
            '.github/PULL_REQUEST_TEMPLATE.md': "PR ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
        }
        
        for file_path, description in recommended_files.items():
            full_path = path / file_path
            if not full_path.exists():
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã¯ã€ä»»æ„ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if file_path.endswith('TEMPLATE'):
                    if not any(full_path.parent.glob(f"{full_path.name}*")):
                        issues.append(ValidationIssue(
                            severity=Severity.LOW,
                            category="structure",
                            message=f"æ¨å¥¨ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}",
                            file_path=str(full_path),
                            suggestion=description,
                            rule_id="MISSING_RECOMMENDED_FILE"
                        ))
                else:
                    issues.append(ValidationIssue(
                        severity=Severity.LOW,
                        category="structure",
                        message=f"æ¨å¥¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}",
                        file_path=str(full_path),
                        suggestion=description,
                        rule_id="MISSING_RECOMMENDED_FILE"
                    ))
        
        return issues

    def _collect_stats(self, workflow: Dict[str, Any]) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’åé›†"""
        stats = {
            'jobs_count': 0,
            'steps_count': 0,
            'uses_actions': [],
            'triggers': [],
        }
        
        if 'jobs' in workflow:
            stats['jobs_count'] = len(workflow['jobs'])
            
            for job in workflow['jobs'].values():
                if isinstance(job, dict) and 'steps' in job:
                    stats['steps_count'] += len(job['steps'])
                    
                    for step in job['steps']:
                        if isinstance(step, dict) and 'uses' in step:
                            action = step['uses'].split('@')[0]
                            if action not in stats['uses_actions']:
                                stats['uses_actions'].append(action)
        
        if 'on' in workflow:
            triggers = workflow['on']
            if isinstance(triggers, list):
                stats['triggers'] = triggers
            elif isinstance(triggers, dict):
                stats['triggers'] = list(triggers.keys())
            else:
                stats['triggers'] = [str(triggers)]
        
        return stats

    def _is_pr_workflow(self, workflow: Dict[str, Any]) -> bool:
        """PRãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if 'on' not in workflow:
            return False
        
        triggers = workflow['on']
        if isinstance(triggers, dict):
            return 'pull_request' in triggers or 'pull_request_target' in triggers
        elif isinstance(triggers, list):
            return 'pull_request' in triggers or 'pull_request_target' in triggers
        
        return False

    def generate_report(self, result: ValidationResult, format_type: str = 'text') -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if format_type == 'json':
            return self._generate_json_report(result)
        elif format_type == 'junit':
            return self._generate_junit_report(result)
        else:
            return self._generate_text_report(result)

    def _generate_text_report(self, result: ValidationResult) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        lines = []
        lines.append("=" * 60)
        lines.append("GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
        lines.append("=" * 60)
        lines.append("")
        
        # çµ±è¨ˆæƒ…å ±
        if result.stats:
            lines.append("ğŸ“Š çµ±è¨ˆæƒ…å ±:")
            for key, value in result.stats.items():
                lines.append(f"  {key}: {value}")
            lines.append("")
        
        # å•é¡Œã®ã‚µãƒãƒªãƒ¼
        critical = len([i for i in result.issues if i.severity == Severity.CRITICAL])
        high = len([i for i in result.issues if i.severity == Severity.HIGH])
        medium = len([i for i in result.issues if i.severity == Severity.MEDIUM])
        low = len([i for i in result.issues if i.severity == Severity.LOW])
        
        lines.append("ğŸ” æ¤œè¨¼çµæœ:")
        lines.append(f"  ç·åˆåˆ¤å®š: {'âœ… åˆæ ¼' if result.passed else 'âŒ ä¸åˆæ ¼'}")
        lines.append(f"  Critical: {critical}")
        lines.append(f"  High:     {high}")
        lines.append(f"  Medium:   {medium}")
        lines.append(f"  Low:      {low}")
        lines.append(f"  è­¦å‘Š:     {len(result.warnings)}")
        lines.append("")
        
        # å•é¡Œè©³ç´°
        if result.issues:
            lines.append("ğŸš¨ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
            lines.append("")
            
            # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_issues = sorted(result.issues, key=lambda x: ['critical', 'high', 'medium', 'low'].index(x.severity.value))
            
            for issue in sorted_issues:
                severity_icon = {
                    Severity.CRITICAL: "ğŸ”´",
                    Severity.HIGH: "ğŸŸ ",
                    Severity.MEDIUM: "ğŸŸ¡",
                    Severity.LOW: "âšª",
                }.get(issue.severity, "â“")
                
                lines.append(f"{severity_icon} [{issue.severity.value.upper()}] {issue.message}")
                lines.append(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {issue.file_path}")
                if issue.line_number:
                    lines.append(f"   ğŸ“ è¡Œ: {issue.line_number}")
                if issue.suggestion:
                    lines.append(f"   ğŸ’¡ ææ¡ˆ: {issue.suggestion}")
                if issue.rule_id:
                    lines.append(f"   ğŸ·ï¸  ãƒ«ãƒ¼ãƒ«: {issue.rule_id}")
                lines.append("")
        
        # è­¦å‘Š
        if result.warnings:
            lines.append("âš ï¸  è­¦å‘Š:")
            lines.append("")
            
            for warning in result.warnings:
                lines.append(f"âš ï¸  {warning.message}")
                lines.append(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {warning.file_path}")
                if warning.suggestion:
                    lines.append(f"   ğŸ’¡ ææ¡ˆ: {warning.suggestion}")
                lines.append("")
        
        return "\n".join(lines)

    def _generate_json_report(self, result: ValidationResult) -> str:
        """JSONå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report_data = {
            'passed': result.passed,
            'stats': result.stats,
            'summary': {
                'total_issues': len(result.issues),
                'critical': len([i for i in result.issues if i.severity == Severity.CRITICAL]),
                'high': len([i for i in result.issues if i.severity == Severity.HIGH]),
                'medium': len([i for i in result.issues if i.severity == Severity.MEDIUM]),
                'low': len([i for i in result.issues if i.severity == Severity.LOW]),
                'warnings': len(result.warnings),
            },
            'issues': [
                {
                    'severity': issue.severity.value,
                    'category': issue.category,
                    'message': issue.message,
                    'file_path': issue.file_path,
                    'line_number': issue.line_number,
                    'column_number': issue.column_number,
                    'suggestion': issue.suggestion,
                    'rule_id': issue.rule_id,
                }
                for issue in result.issues
            ],
            'warnings': [
                {
                    'severity': warning.severity.value,
                    'category': warning.category,
                    'message': warning.message,
                    'file_path': warning.file_path,
                    'line_number': warning.line_number,
                    'column_number': warning.column_number,
                    'suggestion': warning.suggestion,
                    'rule_id': warning.rule_id,
                }
                for warning in result.warnings
            ],
        }
        
        return json.dumps(report_data, indent=2, ensure_ascii=False)

    def _generate_junit_report(self, result: ValidationResult) -> str:
        """JUnit XMLå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        from xml.etree.ElementTree import Element, SubElement, tostring
        from xml.dom import minidom
        
        testsuites = Element('testsuites')
        testsuite = SubElement(testsuites, 'testsuite')
        testsuite.set('name', 'GitHub Actions Validation')
        testsuite.set('tests', str(len(result.issues) + len(result.warnings)))
        testsuite.set('failures', str(len(result.issues)))
        testsuite.set('errors', '0')
        testsuite.set('skipped', str(len(result.warnings)))
        
        for issue in result.issues:
            testcase = SubElement(testsuite, 'testcase')
            testcase.set('classname', f"{issue.category}.{issue.rule_id or 'unknown'}")
            testcase.set('name', issue.message)
            
            failure = SubElement(testcase, 'failure')
            failure.set('message', issue.message)
            failure.text = f"File: {issue.file_path}\nLine: {issue.line_number or 'N/A'}\nSuggestion: {issue.suggestion or 'N/A'}"
        
        for warning in result.warnings:
            testcase = SubElement(testsuite, 'testcase')
            testcase.set('classname', f"{warning.category}.{warning.rule_id or 'unknown'}")
            testcase.set('name', warning.message)
            
            skipped = SubElement(testcase, 'skipped')
            skipped.set('message', warning.message)
        
        # XMLæ–‡å­—åˆ—ã‚’æ•´å½¢
        rough_string = tostring(testsuites, encoding='unicode')
        reparsed = minidom.parseString(rough_string)
        return reparsed.toprettyxml(indent="  ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¾‹:
  %(prog)s /path/to/repository
  %(prog)s --format json --output report.json .
  %(prog)s --config custom-rules.yml /path/to/repo
        """
    )
    
    parser.add_argument('path', nargs='?', default='.',
                        help='æ¤œè¨¼ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)')
    parser.add_argument('-c', '--config', type=str,
                        help='ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('-f', '--format', choices=['text', 'json', 'junit'],
                        default='text', help='å‡ºåŠ›å½¢å¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: text)')
    parser.add_argument('-o', '--output', type=str,
                        help='çµæœã‚’å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='è©³ç´°ãªå‡ºåŠ›ã‚’è¡¨ç¤º')
    parser.add_argument('--version', action='version', version='%(prog)s 1.0.0')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format='%(levelname)s: %(message)s')
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
    validator = WorkflowValidator(args.config)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    try:
        if os.path.isfile(args.path) and args.path.endswith(('.yml', '.yaml')):
            # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
            result = validator.validate_workflow(args.path)
        else:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼
            result = validator.validate_directory(args.path)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = validator.generate_report(result, args.format)
        
        # å‡ºåŠ›
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"çµæœã‚’ {args.output} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
        else:
            print(report)
        
        # çµ‚äº†ã‚³ãƒ¼ãƒ‰
        sys.exit(0 if result.passed else 1)
        
    except Exception as e:
        logging.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(2)


if __name__ == '__main__':
    main()